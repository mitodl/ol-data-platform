import re
from datetime import UTC, datetime

from dagster import (
    AssetExecutionContext,
    AssetKey,
    AssetMaterialization,
    DefaultSensorStatus,
    DynamicPartitionsDefinition,
    MetadataValue,
    SensorEvaluationContext,
    SensorResult,
    asset,
    sensor,
)

edxorg_archive_partitions = DynamicPartitionsDefinition(name="edxorg_archive")


@sensor(
    default_status=DefaultSensorStatus.RUNNING,
    required_resource_keys={"gcp_gcs"},
)
def gcs_edxorg_archive_sensor(context: SensorEvaluationContext):
    dagster_instance = context.instance
    storage_client = context.resources.gcp_gcs.client
    bucket_name = "simeon-mitx-pipeline-main"
    bucket_prefix = "COLD"
    bucket_files = {
        file_
        for file_ in storage_client.list_blobs(bucket_name, prefix=bucket_prefix)
        if re.match(r"COLD/mitx-\d{4}-\d{2}-\d{2}.tar.gz$", file_.name)
        and file_.name.removeprefix("COLD/")
        not in edxorg_archive_partitions.get_partition_keys(
            dynamic_partitions_store=dagster_instance
        )
    }

    assets = []
    for file_ in bucket_files:
        context.log.debug(f"Processing file {file_.name}")
        assets.append(
            AssetMaterialization(
                asset_key=AssetKey(("edxorg", "raw_data_archive")),
                partition=file_.name.removeprefix("COLD/"),
                description=(
                    "Archive of data exported from edx.org for courses run by MIT. "
                    "Generated by https://github.com/openedx/edx-analytics-exporter/"
                ),
                metadata={
                    "source": "edxorg",
                    "path": MetadataValue.path(f"gs://{bucket_name}/{file_.name}"),
                    "creation_date": datetime.strptime(
                        re.search(r"(\d{4}-\d{2}-\d{2})", file_.name).groups()[0],
                        "%Y-%m-%d",
                    ).strftime("%Y-%m-%d"),
                    "size (bytes)": file_.size,
                    "materialization_time": datetime.now(tz=UTC).isoformat(),
                },
            )
        )
        edxorg_archive_partitions.build_add_request(
            partition_keys=[file_.name.removeprefix("COLD/")]
        )

    return SensorResult(asset_events=assets)


@asset(
    required_resource_keys={"gcp_gcs"},
    key_prefix="edxorg",
    deps=[AssetKey(("edxorg", "raw_data_archive"))],
)
def process_edxorg_archive_bundle(context: AssetExecutionContext):
    context.resources.gcp_gcs.client.get_bucket()
    dep: AssetKey = context.job_def.asset_layer.asset_deps.values()[0]
    context.asset


def edxorg_archive_course_snapshot():
    ...
