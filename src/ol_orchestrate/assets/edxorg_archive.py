# - Process the raw_data_archive to extract the per-course assets
# - Model the different asset objects according to their type

import hashlib
import re
import tarfile
from datetime import UTC, datetime
from pathlib import Path

from dagster import (
    AssetKey,
    AssetMaterialization,
    Config,
    DagsterEventType,
    DataVersion,
    DefaultSensorStatus,
    DynamicOut,
    DynamicOutput,
    DynamicPartitionsDefinition,
    EventRecordsFilter,
    MetadataValue,
    MultiPartitionKey,
    OpExecutionContext,
    RunRequest,
    SensorEvaluationContext,
    SensorResult,
    asset,
    op,
    sensor,
)
from dagster._core.definitions.data_version import DATA_VERSION_TAG
from google.cloud import storage
from pydantic import Field

from ol_orchestrate.lib.dagster_helpers import sanitize_mapping_key
from ol_orchestrate.lib.dagster_types.files import DagsterPath
from ol_orchestrate.lib.edxorg import (
    build_mapping_key,
    categorize_archive_element,
    parse_archive_path,
)

edxorg_archive_partitions = DynamicPartitionsDefinition(name="edxorg_archive")
course_and_source_partitions = DynamicPartitionsDefinition(name="course_and_source")
raw_archive_asset_key = AssetKey(("edxorg", "raw_data_archive"))


@sensor(
    default_status=DefaultSensorStatus.RUNNING,
    required_resource_keys={"gcp_gcs"},
)
def gcs_edxorg_archive_sensor(context: SensorEvaluationContext):
    dagster_instance = context.instance
    storage_client = context.resources.gcp_gcs.client
    bucket_name = "simeon-mitx-pipeline-main"
    bucket_prefix = "COLD"
    bucket_files: set[storage.Blob] = {
        file_
        for file_ in storage_client.list_blobs(bucket_name, prefix=bucket_prefix)
        if re.match(r"COLD/mitx-\d{4}-\d{2}-\d{2}.tar.gz$", file_.name)
        and file_.name.removeprefix("COLD/")
        not in edxorg_archive_partitions.get_partition_keys(
            dynamic_partitions_store=dagster_instance
        )
    }

    assets = []
    partition_keys = []
    for file_ in bucket_files:
        context.log.debug("Processing file %s", file_.name)
        partition_key = file_.name.removeprefix("COLD/")
        assets.append(
            AssetMaterialization(
                asset_key=raw_archive_asset_key,
                partition=partition_key,
                description=(
                    "Archive of data exported from edx.org for courses run by MIT. "
                    "Generated by https://github.com/openedx/edx-analytics-exporter/"
                ),
                metadata={
                    "source": "edxorg",
                    "path": MetadataValue.path(f"gs://{bucket_name}/{file_.name}"),
                    "creation_date": datetime.strptime(
                        re.search(r"(\d{4}-\d{2}-\d{2})", file_.name).groups()[0],
                        "%Y-%m-%d",
                    )
                    .replace(tzinfo=UTC)
                    .strftime("%Y-%m-%d"),
                    "size (bytes)": file_.size,
                    "materialization_time": datetime.now(tz=UTC).isoformat(),
                },
                tags={DATA_VERSION_TAG: DataVersion(file_.etag).value},
            )
        )
        partition_keys.append(partition_key)

    return SensorResult(
        asset_events=assets,
        dynamic_partitions_requests=[
            edxorg_archive_partitions.build_add_request(partition_keys=partition_keys)
        ],
        run_requests=[
            RunRequest(
                job_name="retrieve_edx_course_exports",
                run_key=partition,
                partition_key=partition,
            )
            for partition in partition_keys
        ],
    )


@asset(
    partitions_def=edxorg_archive_partitions,
    io_manager_key="gcs_input",
    key=raw_archive_asset_key,
    group_name="edxorg",
)
def edxorg_raw_data_archive():
    ...


class EdxorgArchiveProcessConfig(Config):
    s3_bucket: str = Field(description="S3 bucket to push processed files to.")
    s3_prefix: str = Field(
        default="", description="S3 object key prefix to push processed files to."
    )


@op(
    name="process_edxorg_archive_bundle",
    required_resource_keys={"gcp_gcs"},
    out={
        "course_structure": DynamicOut(is_required=False),
        "course_xml": DynamicOut(is_required=False),
        "forum_mongo": DynamicOut(is_required=False),
        "db_table__assessment_assessment": DynamicOut(is_required=False),
        "db_table__assessment_assessmentfeedback": DynamicOut(is_required=False),
        "db_table__assessment_assessmentfeedback_assessments": DynamicOut(
            is_required=False
        ),
        "db_table__assessment_assessmentfeedback_options": DynamicOut(
            is_required=False
        ),
        "db_table__assessment_assessmentfeedbackoption": DynamicOut(is_required=False),
        "db_table__assessment_assessmentpart": DynamicOut(is_required=False),
        "db_table__assessment_criterion": DynamicOut(is_required=False),
        "db_table__assessment_criterionoption": DynamicOut(is_required=False),
        "db_table__assessment_peerworkflow": DynamicOut(is_required=False),
        "db_table__assessment_peerworkflowitem": DynamicOut(is_required=False),
        "db_table__assessment_rubric": DynamicOut(is_required=False),
        "db_table__assessment_studenttrainingworkflow": DynamicOut(is_required=False),
        "db_table__assessment_studenttrainingworkflowitem": DynamicOut(
            is_required=False
        ),
        "db_table__assessment_trainingexample": DynamicOut(is_required=False),
        "db_table__assessment_trainingexample_options_selected": DynamicOut(
            is_required=False
        ),
        "db_table__auth_user": DynamicOut(is_required=False),
        "db_table__auth_userprofile": DynamicOut(is_required=False),
        "db_table__certificates_generatedcertificate": DynamicOut(is_required=False),
        "db_table__course": DynamicOut(is_required=False),
        "db_table__course_groups_cohortmembership": DynamicOut(is_required=False),
        "db_table__course_structure": DynamicOut(is_required=False),
        "db_table__courseware_studentmodule": DynamicOut(is_required=False),
        "db_table__credit_crediteligibility": DynamicOut(is_required=False),
        "db_table__django_comment_client_role_users": DynamicOut(is_required=False),
        "db_table__examples": DynamicOut(is_required=False),
        "db_table__grades_persistentcoursegrade": DynamicOut(is_required=False),
        "db_table__grades_persistentsubsectiongrade": DynamicOut(is_required=False),
        "db_table__student_anonymoususerid": DynamicOut(is_required=False),
        "db_table__student_courseaccessrole": DynamicOut(is_required=False),
        "db_table__student_courseenrollment": DynamicOut(is_required=False),
        "db_table__student_languageproficiency": DynamicOut(is_required=False),
        "db_table__submissions_score": DynamicOut(is_required=False),
        "db_table__submissions_scoresummary": DynamicOut(is_required=False),
        "db_table__submissions_studentitem": DynamicOut(is_required=False),
        "db_table__submissions_submission": DynamicOut(is_required=False),
        "db_table__teams": DynamicOut(is_required=False),
        "db_table__teams_membership": DynamicOut(is_required=False),
        "db_table__user_api_usercoursetag": DynamicOut(is_required=False),
        "db_table__user_id_map": DynamicOut(is_required=False),
        "db_table__validate": DynamicOut(is_required=False),
        "db_table__wiki_article": DynamicOut(is_required=False),
        "db_table__wiki_articlerevision": DynamicOut(is_required=False),
        "db_table__workflow_assessmentworkflow": DynamicOut(is_required=False),
        "db_table__workflow_assessmentworkflowstep": DynamicOut(is_required=False),
    },
)
def process_edxorg_archive_bundle(
    context: OpExecutionContext,
    config: EdxorgArchiveProcessConfig,
    edxorg_raw_data_archive: DagsterPath,
):
    archive = tarfile.open(edxorg_raw_data_archive)
    dagster_instance = context.instance
    input_asset_materialization_event = dagster_instance.get_event_records(
        event_records_filter=EventRecordsFilter(
            asset_key=context.asset_key_for_input("edxorg_raw_data_archive"),
            event_type=DagsterEventType.ASSET_MATERIALIZATION,
            asset_partitions=[context.partition_key],
        ),
        limit=1,
    )[0]

    while tinfo := archive.next():
        if not tinfo.isdir():
            context.log.debug("Processing archive path %s", tinfo.name)
            asset_info = parse_archive_path(tinfo.name)
            if not asset_info:
                continue
            normalized_source_system = (
                "edge" if "edge" in asset_info["source_system"] else "prod"
            )
            dagster_instance.add_dynamic_partitions(
                course_and_source_partitions.name,
                partition_keys=[
                    MultiPartitionKey(
                        {
                            "course_id": asset_info["course_id"],
                            "source_system": normalized_source_system,
                        }
                    )
                ],
            )
            normalized_extension = (
                "tsv" if asset_info["extension"] == "sql" else asset_info["extension"]
            )
            if table_name := asset_info.get("table_name"):
                output_key = f"db_table__{table_name}"
            else:
                output_key = categorize_archive_element(tinfo.name)
            archive_file = Path(tinfo.name.split("/")[-1])
            archive_file.write_bytes(archive.extractfile(tinfo).read())
            data_version = hashlib.file_digest(
                archive_file.open("rb"), "sha256"
            ).hexdigest()
            mapping_key = build_mapping_key(asset_info)
            context.log.debug(
                "Edxorg output asset mapping key for asset info %s: %s",
                asset_info,
                mapping_key,
            )
            shared_metadata = {
                "path": MetadataValue.path(
                    f"s3://{config.s3_bucket}/{config.s3_prefix}/{'/'.join(mapping_key)}/{data_version}.{normalized_extension}"
                ),
                "object_key": f"{'/'.join(mapping_key)}/{data_version}.{normalized_extension}",
                "source": "edxorg",
                "source_system": normalized_source_system,
                "course_id": asset_info["course_id"],
            }
            yield DynamicOutput(
                (
                    archive_file,
                    f"s3://{config.s3_bucket}/{config.s3_prefix}/{'/'.join(mapping_key)}/{data_version}.{normalized_extension}",
                ),
                output_name=output_key,
                mapping_key=sanitize_mapping_key("/".join(mapping_key)),
                metadata=shared_metadata,
            )
            materialization = AssetMaterialization(
                asset_key=AssetKey(build_mapping_key(asset_info, is_asset_key=True)),
                partition=MultiPartitionKey(
                    {
                        "course_id": asset_info["course_id"],
                        "source_system": normalized_source_system,
                    }
                ),
                metadata=shared_metadata,
                tags={
                    DATA_VERSION_TAG: data_version,
                    "dagster/input_event_pointer/edxorg/raw_data_archive": str(
                        input_asset_materialization_event.storage_id
                    ),
                    "dagster/input_data_version/edxorg/raw_data_archive": input_asset_materialization_event.asset_materialization.tags.get(
                        DATA_VERSION_TAG
                    ),
                },
            )
            yield materialization
